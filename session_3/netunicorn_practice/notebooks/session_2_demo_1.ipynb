{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07cc887-9b2a-4e26-af56-b559ca7e03ed",
   "metadata": {},
   "source": [
    "# Demo 1: netUnicorn basic usage\n",
    "\n",
    "In this demo we will show the basic usage of netUnicorn platform, including pipeline definition, experiment creation, compilation and deployment, and also result analysis.\n",
    "\n",
    "We will need to import some abstractions and prepared tasks for this demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb7d0f-548e-481a-89c7-2dcb1b1351a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote client to connect to remote netunicorn instance\n",
    "from netunicorn.client.remote import RemoteClient\n",
    "\n",
    "# Basic abstractions - pipeline and experiment\n",
    "from netunicorn.base import Pipeline, Experiment\n",
    "\n",
    "# And different prepared tasks:\n",
    "from netunicorn.library.tasks.measurements.ookla_speedtest import SpeedTest           # Ookla SpeedTest\n",
    "from netunicorn.library.tasks.capture.tcpdump import StartCapture, StopNamedCapture   # Start and stop tcpdump\n",
    "from netunicorn.library.tasks.upload.fileio import UploadToFileIO                     # Upload files to an online storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3d72b-a20a-46e2-8541-70be7916cd2d",
   "metadata": {},
   "source": [
    "We imported all the tasks that we will use and now need to create a desired pipeline for the data collection intent.\n",
    "\n",
    "We create a Pipeline object and use `.then` operation to create a new stage: all tasks on this stage would be executed only after the previous stage finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca864121-aa46-432b-8689-fb063f5a7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(StartCapture(filepath=\"/tmp/capture.pcap\", name=\"capture\"))\n",
    "    .then(SpeedTest(name=\"speedtest\"))\n",
    "    .then(StopNamedCapture(start_capture_task_name=\"capture\", name=\"stop_capture\"))\n",
    "    .then(UploadToFileIO(filepath=\"/tmp/capture.pcap\", expires=\"1d\", name=\"upload_data\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37116b28-3c4d-455d-89a2-6477eba7aeed",
   "metadata": {},
   "source": [
    "Now let's connect to our local netUnicorn instance and get nodes that we will use for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ce7e0-a7f5-4722-bac0-16dcf841d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = RemoteClient(endpoint='http://localhost:26611', login='test', password='test')\n",
    "print(f\"netunicorn instance is healthy: {client.healthcheck()}\")\n",
    "\n",
    "nodes = client.get_nodes()\n",
    "print(f\"Nodes: {nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1caa45f-2a50-4655-9da6-fa0b2dcc60de",
   "metadata": {},
   "source": [
    "As you can see, currently we have only one node - local docker host (for purposes of the tutorial). We can deploy any number of pipelines to this host to work in parallel, but now let's just create a simple Experiment with a single pipeline that we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06d6b9-e0f7-4f9c-b216-cb0aafb695ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment().map(pipeline, nodes.take(1))\n",
    "print(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449ced7-e3ec-45d9-834f-b80644dd92d2",
   "metadata": {},
   "source": [
    "Currently experiment is defined, but not yet prepared. For this, we need to send it to the netUnicorn instance and ask to prepare it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eba11d-6c65-4711-a3be-df1db2c05b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_experiment(experiment_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b88e5-bcb0-4587-a59a-bc23f5c38941",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_label = \"session2_demo1_example\"\n",
    "client.prepare_experiment(experiment, experiment_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a1eec-eec4-45c2-ae4e-c652697c7d6e",
   "metadata": {},
   "source": [
    "Preparation consists of compiling a Docker image with all dependencies and code inside and distributing it to all nodes participating in the experiment. See the presentation for additional details.\n",
    "\n",
    "Let's check the experiment status and wait until it's \"READY\" for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3974f8f-6ae5-46e3-a362-bf59303db193",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = client.get_experiment_status(experiment_label)\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b5c13-b589-4d2a-be5a-ae2d5db291d1",
   "metadata": {},
   "source": [
    "When preparation is finished, we can verify that all nodes are ready and start the data collection experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5265c7-0147-48a6-9126-9bb11f4caf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.start_execution(experiment_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410e6e3-2d86-4486-bc9b-1f18d5037c26",
   "metadata": {},
   "source": [
    "Starting the experiment sends a command to all participating nodes to actually start the required scripts or container to execute, and collect results afterward.\n",
    "\n",
    "As with preparation, let's wait until the experiment is \"FINISHED\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888fdff-20e6-4baa-a2b0-870536f67014",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = client.get_experiment_status(experiment_label)\n",
    "info.status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b26ac-6b86-4f78-9506-60498471d1c9",
   "metadata": {},
   "source": [
    "After experiment is finished and we received the full experiment status, we can explore it - see nodes participating in the experiment, their execution results, and execution result of each task in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2007ce-e92b-48d9-b21a-7c299fb2b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from returns.pipeline import is_successful\n",
    "\n",
    "for report in info.execution_result:\n",
    "    print(f\"Node name: {report.node.name}\")\n",
    "    print(f\"Error: {report.error}\")\n",
    "\n",
    "    result, log = report.result  # report stores results of execution and corresponding log\n",
    "    \n",
    "    # result is a returns.result.Result object, could be Success of Failure\n",
    "    print(f\"Result is: {type(result)}\\n\")\n",
    "    data = result.unwrap() if is_successful(result) else result\n",
    "    for key, value in data.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    print()\n",
    "    # we also can explore logs\n",
    "    for line in log:\n",
    "        print(line.strip())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
